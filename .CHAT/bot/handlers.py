import logging
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import Command
from .keyboards import get_main_menu, get_analysis_menu, get_history_menu
from config import BOT_TOKEN, DEBUG_MODE, OPENAI_API_KEY
from storage.sqlite import SQLiteStorage
from storage.redis import RedisStorage
from parser.ozon import OzonParser
from analyzer.ngram import NGramAnalyzer
from analyzer.gpt_processor import GPTProcessor
from exporter.txt import TXTExporter

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/bot.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()
sqlite_storage = SQLiteStorage()
redis_storage = RedisStorage()
ozon_parser = OzonParser()
ngram_analyzer = NGramAnalyzer()
gpt_processor = GPTProcessor(OPENAI_API_KEY)

# –¢–µ–∫—Å—Ç—ã –∫–Ω–æ–ø–æ–∫ reply-–∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã
BUTTON_TEXTS = ["üîç –ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑", "üìä –ò—Å—Ç–æ—Ä–∏—è", "‚ùì –ü–æ–º–æ—â—å", "üì¨ –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å"]

@dp.message(Command("start"))
async def cmd_start(message: types.Message):
    logger.info(f"User {message.from_user.id} started bot")
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –¥–ª—è SEO-–∞–Ω–∞–ª–∏–∑–∞ –∫–∞—Ä—Ç–æ—á–µ–∫ Ozon.", reply_markup=get_main_menu())

@dp.message(Command("analyze"))
async def cmd_analyze(message: types.Message):
    user_id = message.from_user.id
    query = message.text.replace("/analyze", "").strip()
    logger.info(f"User {user_id} requested analysis via command: {query}")
    await process_query(message, user_id, query)

@dp.message(F.text.in_(BUTTON_TEXTS))
async def handle_button_text(message: types.Message):
    user_id = message.from_user.id
    text = message.text
    logger.info(f"User {user_id} pressed button: {text}")
    if text == "üîç –ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑":
        await message.answer("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å, –Ω–∞–ø—Ä–∏–º–µ—Ä: —á–µ—Ö–æ–ª iphone –∏–ª–∏ —Å—Å—ã–ª–∫—É –Ω–∞ —Ç–æ–≤–∞—Ä Ozon", reply_markup=get_main_menu())
    elif text == "üìä –ò—Å—Ç–æ—Ä–∏—è":
        await cmd_history(message)
    elif text == "‚ùì –ü–æ–º–æ—â—å":
        await cmd_help(message)
    elif text == "üì¨ –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å":
        await cmd_feedback(message)

@dp.message()
async def handle_text(message: types.Message):
    user_id = message.from_user.id
    query = message.text.strip()
    logger.info(f"User {user_id} sent text: {query}")
    if query not in BUTTON_TEXTS:
        await process_query(message, user_id, query)

async def process_query(message: types.Message, user_id: int, query: str):
    logger.info(f"Processing query for user {user_id}: {query}")
    try:
        if not query:
            logger.info(f"User {user_id} sent empty query")
            await message.answer("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å, –Ω–∞–ø—Ä–∏–º–µ—Ä: —á–µ—Ö–æ–ª iphone –∏–ª–∏ —Å—Å—ã–ª–∫—É –Ω–∞ —Ç–æ–≤–∞—Ä Ozon", reply_markup=get_main_menu())
            return
        if not redis_storage.check_request_limit(user_id):
            logger.warning(f"User {user_id} exceeded request limit")
            await message.answer("–õ–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ (5/—á–∞—Å) –∏—Å—á–µ—Ä–ø–∞–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.", reply_markup=get_main_menu())
            return
        parse_result = await ozon_parser.parse_search(user_id, query)
        logger.info(f"Parse result for user {user_id}: {parse_result}")
        if "error" in parse_result:
            logger.error(f"Parse error for user {user_id}: {parse_result['error']}")
            await message.answer(f"–û—à–∏–±–∫–∞: {parse_result['error']}", reply_markup=get_main_menu())
            return
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º GPT –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ n-–≥—Ä–∞–º–º
        ngram_result = gpt_processor.process_ngrams(query, parse_result)
        logger.info(f"NGram result for user {user_id}: {ngram_result}")
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ, —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–º —Å —Ç–µ–∫—É—â–µ–π –ª–æ–≥–∏–∫–æ–π
        ngram_formatted = {
            'unigrams': [(item['phrase'], item['count']) for item in ngram_result if len(item['phrase'].split()) == 1],
            'bigrams': [(item['phrase'], item['count']) for item in ngram_result if len(item['phrase'].split()) == 2],
            'trigrams': [(item['phrase'], item['count']) for item in ngram_result if len(item['phrase'].split()) == 3]
        }
        sqlite_storage.add_history(user_id, query, {"parse": parse_result, "ngrams": ngram_formatted})
        await message.answer("–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω!", reply_markup=get_analysis_menu())
        logger.info(f"Sending keyboard to user {user_id}")
        if DEBUG_MODE:
            logger.debug(f"Debug mode: Sending immediate keyboard to user {user_id}")
            await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=get_main_menu())
    except Exception as e:
        logger.error(f"Error in process_query for user {user_id}: {str(e)}", exc_info=True)
        await message.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ.", reply_markup=get_main_menu())
        if DEBUG_MODE:
            await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=get_main_menu())

@dp.message(Command("history"))
async def cmd_history(message: types.Message):
    user_id = message.from_user.id
    logger.info(f"User {user_id} requested history")
    analyses = sqlite_storage.get_history(user_id)
    if not analyses:
        logger.info(f"User {user_id} has empty history")
        await message.answer("–ò—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞.", reply_markup=get_main_menu())
        return
    formatted_analyses = [(query, timestamp) for query, _, timestamp in analyses]
    await message.answer("–í–∞—à–∏ –∞–Ω–∞–ª–∏–∑—ã:", reply_markup=get_history_menu(formatted_analyses))

@dp.message(Command("help"))
async def cmd_help(message: types.Message):
    logger.info(f"User {message.from_user.id} requested help")
    await message.answer("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /analyze –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞, /history –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏—Å—Ç–æ—Ä–∏–∏.", reply_markup=get_main_menu())

@dp.message(Command("feedback"))
async def cmd_feedback(message: types.Message):
    logger.info(f"User {message.from_user.id} requested feedback")
    await message.answer("–ù–∞–ø–∏—à–∏—Ç–µ –≤–∞—à –æ—Ç–∑—ã–≤:", reply_markup=get_main_menu())

@dp.callback_query()
async def process_callback(callback: types.CallbackQuery):
    user_id = callback.from_user.id
    data = callback.data
    logger.info(f"User {user_id} clicked callback: {data}")
    try:
        if data.startswith("top_") or data == "all_keys":
            analyses = sqlite_storage.get_history(user_id)
            if not analyses:
                logger.info(f"User {user_id} has empty history for callback")
                await callback.message.answer("–ò—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞.", reply_markup=get_main_menu())
                return
            latest = analyses[0]
            ngrams = latest[1]["ngrams"]
            limit = 10 if data == "top_10" else 30 if data == "top_30" else None
            keys = ngram_analyzer.get_top_keys(ngrams, limit)
            logger.info(f"Keys for user {user_id}: {keys}")
            if not keys:
                logger.info(f"No keys found for user {user_id}")
                await callback.message.answer("–ö–ª—é—á–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.", reply_markup=get_main_menu())
                return
            response = "\n".join(f"{key}: {count}" for key, count in keys)
            if len(response) > 4096:
                logger.warning(f"Response too large for user {user_id}, suggesting TXT download")
                await callback.message.answer("–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ '–°–∫–∞—á–∞—Ç—å TXT'.", reply_markup=get_main_menu())
            else:
                await callback.message.answer(response, reply_markup=get_main_menu())
        elif data == "download_txt":
            logger.info(f"User {user_id} requested TXT download")
            analyses = sqlite_storage.get_history(user_id)
            if not analyses:
                await callback.message.answer("–ò—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞.", reply_markup=get_main_menu())
                return
            latest = analyses[0]
            ngrams = latest[1]["ngrams"]
            keys = ngram_analyzer.get_top_keys(ngrams)
            txt_file = TXTExporter.export_to_txt(keys)
            await callback.message.answer_document(txt_file, reply_markup=get_main_menu())
        elif data == "repeat":
            logger.info(f"User {user_id} requested repeat analysis")
            await callback.message.answer("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –¥–ª—è –Ω–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:", reply_markup=get_main_menu())
    except Exception as e:
        logger.error(f"Error in callback for user {user_id}: {str(e)}", exc_info=True)
        await callback.message.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞.", reply_markup=get_main_menu())
    await callback.answer()