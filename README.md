# ReelifyAI Bot

**ReelifyAI Bot** — это Telegram-бот, разработанный для анализа поисковых запросов на маркетплейсе Ozon. Бот парсит страницы поиска и карточки товаров, извлекает данные (заголовки, описания, цены, остатки) и выполняет анализ n-грамм для выявления ключевых слов и фраз. Проект направлен на помощь в SEO-оптимизации, маркетинговых исследованиях и анализе трендов на основе запросов пользователей.

## Назначение проекта

ReelifyAI Bot предназначен для:
- **Анализа поисковых запросов**: Извлечение ключевых слов (n-грамм) из заголовков, описаний и других данных товаров на Ozon.
- **SEO-оптимизации**: Помощь продавцам в составлении релевантных заголовков и описаний для повышения видимости товаров.
- **Маркетинговых исследований**: Анализ популярных характеристик товаров (например, «силиконовый чехол» для iPhone или «ботинки на меху» для зимней обуви).
- **Автоматизации**: Упрощение сбора данных с маркетплейса без ручного анализа.

Бот обрабатывает запросы пользователей в Telegram, выполняет парсинг Ozon с использованием Playwright или Selenium и возвращает результаты в виде списка n-грамм с частотой их появления.

## Основные функции

1. **Парсинг Ozon**:
   - Сбор данных с поисковых страниц (до 50 карточек товаров).
   - Извлечение заголовков, цен, остатков, альтернативных текстов изображений и хлебных крошек.
   - Парсинг страниц товаров для получения подробных описаний.
2. **Анализ n-грамм**:
   - Извлечение униграмм, биграмм и триграмм из собранных данных.
   - Фильтрация стоп-слов, брендов и технических кодов.
   - Лемматизация с использованием `pymorphy3` для приведения слов к нормальной форме.
3. **Кэширование**:
   - Использование Redis для хранения результатов парсинга (TTL 24 часа).
4. **Интеграция с Telegram**:
   - Обработка текстовых запросов через библиотеку `aiogram`.
   - Отправка результатов пользователю в виде списка ключевых фраз.
5. **Обход антибот-защиты**:
   - Эмуляция браузера с помощью Playwright (или Selenium).
   - Использование куки, заголовков и случайных задержек для минимизации блокировок.

## Технологический стек

- **Язык программирования**: Python 3.10+
- **Парсинг**:
  - Playwright (основной инструмент для работы с динамическим контентом).
  - Selenium (резервный вариант).
- **Анализ текста**:
  - NLTK для токенизации и извлечения n-грамм.
  - `pymorphy3` для лемматизации.
  - Scikit-learn (`TfidfVectorizer`) для анализа TF-IDF (в разработке).
- **Кэширование**: Redis
- **Telegram API**: `aiogram` для асинхронной обработки сообщений.
- **Логирование**: Python `logging` с выводом в файл (`logs/bot.log`) и консоль.
- **Зависимости**: Управление через `pip` (см. `requirements.txt`).
- **Конфигурация**: Файл `config.py` для хранения констант (токены, URL, лимиты).

## Структура проекта

```
ReelifyAI_bot/
├── analyzer/
│   ├── gpt_processor.py   
│   ├── ngram.py          
│   ├── stopwords.py      
│   └── __init__.py
├── bot/
│   ├── handlers.py    
│   ├── keyboards.py   
│   └── __init__.py
├── exporter
│   ├── txt.py 
│   └── __init__.py
├── filters
│   └── stopwords
│   │   └── static_stopwords.txt
│   │   └── static_stop_phrases.txt
│   │   └── одежда.txt
│   └── stopwords_manager.py
│
├── logs/
│   └── bot.log 
│
├── parser/
│   ├── ozon.py   
│   ├── proxy.py  
│   └── __init__.py
├── storage/
│   ├── redis.py  
│   ├── sqlite.py 
│   └── __init__.py
├── config.py     
├── main.py       
├── requirements.txt 
├── README.md        
└── .gitignore       
```

Структура проекта подробнее:
ReelifyAI_bot/
├── analyzer/
│   ├── gpt_processor.py
│   │   # Обрабатывает данные с помощью ИИ (типа ChatGPT), чтобы предложить крутые ключевые слова. Если ИИ не работает, использует обычный анализ слов.
│   ├── ngram.py
│   │   # Разбивает текст на слова или фразы (ключевые слова) и считает, как часто они встречаются. Убирает лишние слова и приводит текст к единой форме (например, «бегающий» → «бегать»).
│   ├── stopwords.py
│   │   # Управляет списком слов и фраз, которые надо игнорировать (например, «и», «купить дёшево»), чтобы ключевые слова были полезными.
│   └── __init__.py
│       # Делает папку analyzer пакетом, чтобы код из неё можно было использовать в других частях проекта.
├── bot/
│   ├── handlers.py
│   │   # Обрабатывает сообщения в Telegram. Реагирует на команды (например, /start) или запросы (например, «чехлы для айфона») и запускает поиск и анализ.
│   ├── keyboards.py
│   │   # Создаёт кнопки в Telegram, чтобы пользователи могли, например, посмотреть больше ключевых слов или уточнить запрос.
│   └── __init__.py
│       # Делает папку bot пакетом для удобной работы с кодом.
├── exporter/
│   ├── txt.py
│   │   # Сохраняет результаты (список ключевых слов) в текстовые файлы, чтобы их можно было скачать или отправить.
│   └── __init__.py
│       # Делает папку exporter пакетом, чтобы использовать txt-файл в проекте.
├── filters/
│   └── stopwords/
│       ├── static_stopwords.txt
│       │   # Список простых слов, которые не нужны (например, «и», «на»), чтобы не мешали при анализе.
│       ├── static_stop_phrases.txt
│       │   # Список фраз, которые надо пропускать (например, «бесплатная доставка»), чтобы результаты были чище.
│       ├── одежда_75.txt
│           # Слова, связанные с одеждой (например, «модный»), которые игнорируются, чтобы результаты поиска одежды были точнее.
│   └── stopwords_manager.py
│       # Загружает и объединяет списки слов для фильтрации текста, чтобы убрать всё лишнее.
├── logs/
│   └── bot.log
│       # Файл с записями о работе бота: что он делает, где ошибся, что нашёл. Помогает найти и исправить проблемы.
├── parser/
│   ├── ozon.py
│   │   # Собирает данные с Ozon: ищет товары, берёт названия, цены, описания. Работает через Playwright, а если не получается — через Selenium.
│   ├── proxy.py
│   │   # Управляет прокси-серверами, чтобы Ozon не заблокировал бота, думая, что это робот.
│   └── __init__.py
│       # Делает папку parser пакетом для использования в коде.
├── storage/
│   ├── redis.py
│   │   # Сохраняет результаты поиска в Redis (быстрая база данных), чтобы не искать одно и то же. Хранит данные 24 часа.
│   ├── sqlite.py
│   │   # Сохраняет данные в SQLite (локальная база), чтобы хранить запросы пользователей или результаты надолго.
│   └── __init__.py
│       # Делает папку storage пакетом для работы с redis и sqlite.
├── config.py
│   # Файл с настройками: токен бота для Telegram, ссылка на поиск Ozon, лимиты запросов и другие параметры.
├── main.py
│   # Главный файл, который запускает бота, подключает Telegram, Redis и SQLite, чтобы всё работало.
├── requirements.txt
│   # Список нужных библиотек Python (например, aiogram для Telegram, Playwright для парсинга), чтобы установить всё одной командой.
├── README.md
│   # Инструкция по проекту: что делает бот, как его установить, как пользоваться и как помочь улучшить.
└── .gitignore
    # Указывает, какие файлы не загружать в Git, например, временные файлы, логи или настройки с секретными ключами.

### Описание файлов и директорий

- **`bot/handlers.py`**: Логика обработки сообщений Telegram. Обрабатывает команды (`/start`), текстовые запросы и callback-кнопки. Вызывает парсер и анализатор.
- **`parser/ozon.py`**: Основной парсер Ozon. Использует Playwright для загрузки страниц поиска и товаров, извлекает данные с помощью BeautifulSoup. Поддерживает Selenium как резерв.
- **`analyzer/ngram.py`**: Модуль анализа n-грамм. Токенизирует текст, лемматизирует, фильтрует стоп-слова и бренды, возвращает частотные n-граммы.
- **`analyzer/stopwords.py`**: Список стоп-слов для фильтрации.
- **`storage/redis.py`**: Интеграция с Redis для кэширования результатов парсинга.
- **`config.py`**: Константы (токен бота, URL Ozon, лимиты запросов, ключи API).
- **`main.py`**: Запуск бота, инициализация Redis и `aiogram`.
- **`requirements.txt`**: Список зависимостей (например, `playwright`, `aiogram`, `redis`, `beautifulsoup4`, `nltk`, `pymorphy3`).
- **`logs/bot.log`**: Логи ошибок, дебаг-сообщений и информации о парсинге.
- **`.gitignore`**: Игнорирует временные файлы, виртуальное окружение и логи.

## Установка и запуск

### Требования

- Python 3.10+
- Redis (локально или в Docker)
- Playwright (`pip install playwright`, затем `playwright install`)
- Selenium (опционально, с WebDriver для Edge)
- Доступ к Telegram API (токен бота)
- Доступ к Ozon (валидные куки для обхода антибота)

"""
Проблемы, с которыми мы бьёмся (июнь 2025)
Ozon блокирует бота: Сайт думает, что бот — не человек, и не даёт искать. Пытаемся обойти это с прокси и притворяемся обычным браузером, но скорее всего нужно уже переходить на использование РФ-прокси.
Нет описаний товаров: Бот находит названия и цены, но не может достать подробные описания, из-за чего ключевые слова получаются слабые (например, нет «на меху» для ботинок). Чиним поиск по страницам товаров.
Медленно работает: Поиск занимает до 68 секунд, потому что бот проверяет товары по одному. Хотим ускорить это.
Слабые ключевые слова: Из-за проблем с описаниями список слов короткий и не очень полезный. Работаем над улучшением анализа.
"""

### Использование

1. Откройте Telegram, найдите вашего бота (например, `@ReelifyAI_bot`).
2. Отправьте команду `/start` для инициализации.
3. Введите запрос, например, «ботинки зимние женские» или «чехлы iphone».
4. Бот вернёт список n-грамм с частотой их появления, например:
   ```
   зимние ботинки: 2
   женские ботинки: 1
   демисезонные ботинки: 1
   ```

## Текущие проблемы и задачи

На текущем этапе разработки (июнь 2025) мы сталкиваемся со следующими проблемами:

### 1. Антибот-защита Ozon
- **Проблема**: Playwright не находит селекторы (`.tile-root`, `[data-widget='searchResultsV2']`), что указывает на возможную антибот-защиту или редирект.
- **Симптомы**:
  - Ошибка: `No valid selector found for search results`.
  - Длительное время обработки запросов (до 68 секунд).
- **Решения в работе**:
  - Анализ `ozon_error_*.html` и `ozon_error_*.png` для выявления капчи или редиректа.
  - Добавление прокси через `proxybroker` для смены IP.
  - Усиление эмуляции браузера (случайные действия, обновлённые заголовки).
  - Проверка редиректов через отслеживание конечного URL.
- **Следующие шаги**:
  - Проверить содержимое `ozon_error_*.html` на наличие антибота.
  - Интеграция прокси для обхода блокировок.

### 2. Пустое поле `product_descriptions`
- **Проблема**: Парсер не извлекает описания со страниц товаров, что снижает качество n-грамм.
- **Симптомы**:
  - Результаты n-грамм для «ботинки зимние женские» ограничены:
    ```
    зимние ботинки: 2
    женские ботинки: 1
    демисезонные ботинки: 1
    ```
    Ожидаются более богатые данные: «на меху», «ботинки на платформе».
  - Логи показывают: `No product description found for URL`.
- **Решения в работе**:
  - Обновление селекторов для описаний (`.tsBody500Medium`, `[data-widget='webCharacteristics']`).
  - Увеличение таймаутов и использование `wait_until='networkidle'`.
  - Проверка JavaScript-рендеринга через Playwright.
- **Следующие шаги**:
  - Анализ `debug_ozon_product_*.html` для проверки наличия описаний.
  - Добавление кликов на «Подробнее» для раскрытия контента.

### 3. Низкая производительность
- **Проблема**: Обработка запроса занимает до 68 секунд из-за последовательного парсинга страниц товаров.
- **Решения в работе**:
  - Ограничение количества парсируемых страниц товаров (`max_product_pages = 20`).
  - Оптимизация задержек в Playwright.
- **Следующие шаги**:
  - Асинхронный парсинг страниц товаров.
  - Кэширование промежуточных результатов.

### 4. Ограниченные n-граммы
- **Проблема**: Из-за пустого `product_descriptions` результаты n-грамм недостаточно информативны.
- **Решения в работе**:
  - Улучшение фильтрации в `ngram.py` для извлечения n-грамм из заголовков.
  - Добавление TF-IDF анализа для повышения качества ключевых фраз.
- **Следующие шаги**:
  - Группировка n-грамм по ВЧ/СЧ/НЧ.
  - Интеграция GPT для генерации рекомендаций по ключевым словам.

## Планы развития

1. **Обход антибота**:
   - Интеграция прокси через `proxybroker`.
   - Использование API Ozon (если доступно).
2. **Оптимизация производительности**:
   - Параллельный парсинг страниц товаров.
   - Сокращение задержек без потери стабильности.
3. **Улучшение анализа**:
   - Группировка n-грамм по частотности.
   - Интеграция TF-IDF для выделения значимых фраз.
   - Генерация рекомендаций для продавцов (например, «добавьте ‘на меху’ в заголовок»).
4. **Расширение функционала**:
   - Поддержка других маркетплейсов (Wildberries, Яндекс.Маркет).
   - Анализ изображений товаров для извлечения атрибутов.
5. **Интерфейс**:
   - Добавление интерактивных кнопок для выбора категорий или фильтров.
   - Визуализация результатов (графики частотности n-грамм).

## Как внести вклад

1. **Форкните репозиторий** и клонируйте его локально.
2. **Создайте ветку** для вашей задачи:
   ```bash
   git checkout -b feature/your-feature
   ```
3. **Установите зависимости** и настройте окружение (см. выше).
4. **Следуйте PEP 8** для кода.
5. **Добавьте тесты** (в разработке, пока используйте ручное тестирование через Telegram).
6. **Создайте Pull Request** с описанием изменений.

### Пример задач для контрибьюторов

- Реализовать асинхронный парсинг страниц товаров.
- Добавить поддержку прокси через `proxybroker`.
- Разработать модуль анализа TF-IDF в `ngram.py`.
- Создать тесты для `ozon.py` и `ngram.py`.

## Лицензия

Проект распространяется под лицензией MIT. См. файл `LICENSE` для подробностей.

## Контакты

- **Автор**: [Ваше имя]
- **Email**: [Ваш email]
- **GitHub Issues**: Для багов и предложений используйте [Issues](https://github.com/your-username/ReelifyAI_bot/issues).

---

**ReelifyAI Bot** — это мощный инструмент для анализа данных маркетплейсов, который продолжает развиваться. Присоединяйтесь к проекту, чтобы улучшить его функционал и помочь продавцам достигать новых высот!